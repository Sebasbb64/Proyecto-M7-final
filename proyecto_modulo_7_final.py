# -*- coding: utf-8 -*-
"""Proyecto_modulo_7_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s6wjdD_5CQOZ15UXcpAOqvgkaLNZ8UVE

Hipótesis del Proyecto: Predicción de Sentimientos en Reviews de Clientes
Objetivo General:

Desarrollar un modelo predictivo eficaz que pueda clasificar automáticamente los sentimientos expresados en las reviews de clientes, permitiendo una comprensión rápida y cuantitativa de la satisfacción del usuario con respecto a una aplicación específica.

Objetivos Específicos:

Recopilación de Datos:
Obtener un conjunto de datos representativo que contenga reviews de clientes de la aplicación.
Incluir diversidad en términos de longitudes de texto, estilos de expresión y variaciones de sentimientos.
Preprocesamiento de Datos:
Llevar a cabo la limpieza de datos para eliminar información redundante o ruido, como etiquetas HTML, signos de puntuación innecesarios y caracteres especiales.
Realizar tokenización y lematización para reducir las palabras a su forma base.
Análisis Exploratorio de Datos (EDA):
Realizar un análisis exploratorio de los datos para comprender la distribución de las clases de sentimientos (positivo, neutral, negativo).
Visualizar la frecuencia de palabras clave y patrones en las reviews.
Creación del Modelo:
Seleccionar un algoritmo de aprendizaje supervisado adecuado para la clasificación de sentimientos, como regresión logística o Random Forest.
Utilizar técnicas de vectorización (TF-IDF, Word Embeddings) para representar las reviews de manera numérica.
Dividir los datos en conjuntos de entrenamiento y prueba para evaluar la capacidad predictiva del modelo.
Entrenamiento y Evaluación del Modelo:
Entrenar el modelo utilizando el conjunto de entrenamiento y ajustar los hiperparámetros según sea necesario.
Evaluar el rendimiento del modelo utilizando métricas como precisión, recall, F1-score y matriz de confusión.
Optimización del Modelo:
Realizar ajustes en el modelo, como cambiar el umbral de decisión, para equilibrar la precisión y el recall según las necesidades específicas de la aplicación.
Considerar la posibilidad de probar con otros algoritmos o realizar optimización de hiperparámetros para mejorar el rendimiento.
Despliegue y Uso en Producción:
Desplegar el modelo entrenado en un entorno de producción para realizar predicciones en tiempo real.
Integrar la funcionalidad del modelo en la aplicación para procesar automáticamente las nuevas reviews.
Monitoreo Continuo y Retroalimentación:
Implementar un sistema de monitoreo para evaluar continuamente el rendimiento del modelo en condiciones de uso real.
Recopilar retroalimentación de los usuarios sobre la precisión de las predicciones y utilizarla para realizar mejoras iterativas.
Resultados Esperados:

Se espera lograr un modelo preciso y generalizable capaz de predecir con eficacia los sentimientos expresados en las reviews de los clientes.
La implementación del modelo debería mejorar la capacidad de la aplicación para comprender y responder a las necesidades y expectativas de los usuarios.
La retroalimentación positiva y la mejora continua deberían reflejar el éxito del modelo en la predicción de sentimientos y la mejora de la experiencia del usuario.
Esta hipótesis proporciona una guía general para el desarrollo y la implementación del modelo, centrándose en los pasos clave y los objetivos específicos del proyecto.

##Realizar un review del contexto de las palabras con mayor frecuencia aparecidas en el wordcloud
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import unidecode
import re
import nltk
import joblib
from gensim.models import Word2Vec
from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
from yellowbrick.classifier import ConfusionMatrix
from yellowbrick.classifier import ClassificationReport
from sklearn.neighbors import KNeighborsClassifier
from sklearn.utils.multiclass import unique_labels
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from wordcloud import WordCloud

nltk.download('wordnet')

nltk.download('stopwords')

nltk.download('punkt')


"""## Funciones"""

def predecir(review, vectorizer, logistic_regression):

    vector_opinion_example = vectorizer.transform([review])
    sentimiento = logistic_regression.predict(vector_opinion_example)[0]

    if sentimiento == 1:
        print('La opinión tiene un sentimiento: Positivo')
    elif sentimiento == -1:
        print('La opinión tiene un sentimiento: Negativo')
    elif sentimiento == 0:
        print('La opinión tiene un sentimiento: Neutral')
    else:
        print('La opinión tiene un sentimiento no identificado')

    return sentimiento

def generar_wordcloud(texto):
    # Tokenizar el texto
    tokens = nltk.word_tokenize(texto)

    # Crear un objeto Text de NLTK
    texto_nltk = Text(tokens)

    # Generar concordancia para una palabra específica o lista de palabras
    palabras_frecuentes = texto_nltk.concordance_list("palabra_frecuente", width=80, lines=30)

    # Imprimir contextos de las palabras más frecuentes
    for concordancia in palabras_frecuentes:
        print(concordancia.line)

df = pd.read_csv('googleplaystore.csv')

df2 = pd.read_csv('googleplaystore_user_reviews.csv')

STOP_WORDS_EN = stopwords.words('english')

lemmatizer = nltk.WordNetLemmatizer()

df.head(25)

df.info()

df.nunique()

df['Category'].value_counts()

df['Content Rating'].value_counts()

# Calcular el recuento de aplicaciones en cada categoría
categoria_recuento = df['Category'].value_counts()
print(categoria_recuento)

df.describe()

# Seleccionar las principales categorías (por ejemplo, las 5 principales)
top_categorias = categoria_recuento.head(5).index
print(top_categorias)

# Filtrar el DataFrame para incluir solo las aplicaciones de las principales categorías
df_top_categorias = df[df['Category'].isin(top_categorias)]
print(df_top_categorias)

sns.set(style="whitegrid")

# Crear un diagrama de violín para las principales categorías
plt.figure(figsize=(12, 8))
sns.violinplot(x='Category', y='Rating', data=df_top_categorias, palette='muted', inner='quartile')
plt.title('Distribución de Calificaciones en las Principales Categorías')
plt.xlabel('Categoría')
plt.ylabel('Calificación')
plt.xticks(rotation=45)
plt.show()

# Gráfico de barras para mostrar la distribución de las categorías
plt.figure(figsize=(12, 6))
df_top_categorias['Category'].value_counts().plot(kind='bar', color='skyblue')
plt.title('Distribución de Categorías')
plt.xlabel('Categoría')
plt.ylabel('Cantidad')
plt.xticks(rotation=90)
plt.show()

# Gráfico de barras para mostrar el conteo de calificaciones
plt.figure(figsize=(12, 6))
df_top_categorias['Rating'].value_counts().sort_index().plot(kind='bar', color='orange')
plt.title('Conteo de Calificaciones')
plt.xlabel('Calificación')
plt.ylabel('Cantidad')
plt.xticks(rotation=45)
plt.show()

# Gráfico de pastel para mostrar la proporción de aplicaciones gratuitas y de pago
plt.figure(figsize=(6, 6))
df_top_categorias['Type'].value_counts().plot(kind='pie', autopct='%1.1f%%', colors=['lightgreen', 'lightcoral'])
plt.title('Proporción de Aplicaciones Gratuitas y de Pago')
plt.ylabel('')
plt.show()

"""## Analisis del dataframe 2"""

df2.head()

df2.info()

df2.describe()

df2.nunique()

df2['Sentiment'].value_counts()

df2['Sentiment_Polarity'].value_counts()

df2['Sentiment_Subjectivity'].value_counts()

df2_clean = df2.dropna()

df2_clean.info()

# Calcular el recuento de aplicaciones en cada categoría
categoria_recuento2 = df2_clean['Sentiment'].value_counts(5)
print(categoria_recuento)

top_categorias2 = categoria_recuento2.head(5).index
print(top_categorias)

# Filtrar el DataFrame para incluir solo las aplicaciones de las principales categorías
df_top_categorias2 = df2_clean[df2_clean['Sentiment'].isin(top_categorias)]
print(df_top_categorias2)

sns.set(style="whitegrid")

# Gráfico de barras para mostrar la distribución de las categorías de sentimientos
plt.figure(figsize=(6, 4))
sns.countplot(x='Sentiment', data= df2_clean, palette='pastel')
plt.title('Distribución de Sentimientos')
plt.xlabel('Sentimiento')
plt.ylabel('Cantidad')
plt.show()

def clean_text(text):

    #Convetir a minúscula
    text2 = text.lower()

    #Quitar acentos
    text2 = unidecode.unidecode(text2)


    text2 = re.sub('[^a-zA-Z]', ' ', text2)

    #Remover puntuación
    text2 =re.sub("&lt;/?.*?&gt;"," &lt;&gt; ",text2)

    #Remover dígitos y carácteres especiales
    text2 = re.sub("(\\d|\\W)+"," ",text2)

    # Removemos tags HTML
    text2 = re.sub(re.compile('((http|https):\/\/[\w\-_]+(\.[\w\-_]+)+([\w\-\.,@?^=%&amp;:/~\+#]*[\w\-\@?^=%&amp;/~\+#])?)'), '', text2)

    # Tomamos solo las palabras
    text2 = re.sub('[^A-Za-z0-9]+', ' ', text2)

    # Tokenización
    text2 = nltk.word_tokenize(text2)

    # Removemos las palabras de parada
    text2 = [word for word in text2 if word not in STOP_WORDS_EN]

    # Lematizamos
    text2 = [lemmatizer.lemmatize(token, pos="v") for token in text2]
    text2 = [lemmatizer.lemmatize(token) for token in text2]

    # Unimos las palabras
    text2 = ' '.join(text2)

    return text2

df2_clean['Texto_Limpio'] = df2_clean['Translated_Review'].apply(clean_text)

df2_clean.head(100)

df2_clean.info()

sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}

df2_clean['Sentiment_Numeric'] = df2_clean['Sentiment'].map(sentiment_mapping)

df2_clean.head(25)

sentiment_counts = df2_clean['Sentiment_Numeric'].value_counts()

# Grafico de barras para mosrar los valores la cada categoria de la columna Sentiment_Numeric
plt.bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'gray', 'red'])
plt.title('Cantidad de valores en Sentiment_Numeric')
plt.xlabel('Sentiment_Numeric')
plt.ylabel('Cantidad')
plt.show()

df_clean_negative = df2_clean[df2_clean['Sentiment_Numeric']== -1]['Texto_Limpio']

df_clean_positive = df2_clean[df2_clean['Sentiment_Numeric']== 1]['Texto_Limpio']

df_clean_neutral = df2_clean[df2_clean['Sentiment_Numeric']== 0]['Texto_Limpio']

df_clean_negative

df_clean_positive

df_clean_neutral

df_clean_negative.apply (lambda X: len(X))

df_clean_positive.apply (lambda X: len(X))

df_clean_neutral.apply (lambda X: len(X))

negative_text = ' '.join(df_clean_negative)

positive_text=' '.join(df_clean_positive)

neutral_text=' '.join(df_clean_neutral)

wordcloud_neg = WordCloud(width = 800, height = 800,
                background_color='black',
                min_font_size = 10).generate(negative_text)

wordcloud_pos = WordCloud(width = 800, height = 800,
                background_color ='black',
                min_font_size = 10).generate(positive_text)

wordcloud_neu = WordCloud(width = 800, height = 800,
                background_color ='black',
                min_font_size = 10).generate(neutral_text)

words_wordcloud_neg = wordcloud_neg.words_.keys()

words_wordcloud_pos = wordcloud_pos.words_.keys()

words_wordcloud_neu = wordcloud_neu.words_.keys()

diferent_words_wordcloud_neg = words_wordcloud_neg - words_wordcloud_pos

diferent_words_wordcloud_pos = words_wordcloud_pos - words_wordcloud_neg

diferent_words_wordcloud_neu = words_wordcloud_neu

print("Palabras diferentes en la primera nube de palabras:", diferent_words_wordcloud_neg)
print("Palabras diferentes en la segunda nube de palabras:", diferent_words_wordcloud_pos)
print("Palabras diferentes en la segunda nube de palabras:", diferent_words_wordcloud_neu)

text_wordcloud_neg = " ".join(diferent_words_wordcloud_neg)

text_wordcloud_pos = " ".join(diferent_words_wordcloud_pos)

text_wordcloud_neu = " ".join(diferent_words_wordcloud_neu)

wordcloud_neg = WordCloud(width=800, height=800, background_color='white').generate(text_wordcloud_neg)

wordcloud_pos = WordCloud(width=800, height=800, background_color='white').generate(text_wordcloud_pos)

wordcloud_neu = WordCloud(width=800, height=800, background_color='white').generate(text_wordcloud_neu)

plt.figure(figsize=(5, 5))
plt.imshow(wordcloud_neg, interpolation='bilinear')
plt.title('Nube de Palabras negativa')
plt.axis('off')
plt.show()

plt.figure(figsize=(5, 5))
plt.imshow(wordcloud_pos, interpolation='bilinear')
plt.title('Nube de Palabras Positiva')
plt.axis('off')
plt.show()

plt.figure(figsize=(5, 5))
plt.imshow(wordcloud_neu, interpolation='bilinear')
plt.title('Nube de Palabras Neutral')
plt.axis('off')
plt.show()

df_train, df_test, y_train, y_test = train_test_split(df2_clean['Texto_Limpio'], df2_clean['Sentiment_Numeric'], test_size=0.2, random_state=42)

df_train

df_test

vectorizer = TfidfVectorizer()
X_tfidf_train = vectorizer.fit_transform(df_train)
X_tfidf_test =vectorizer.transform(df_test)
joblib.dump(vectorizer,"vectorizer.pkl")

logistic_regression = LogisticRegression(max_iter=1000, random_state=30)

logistic_regression.fit(X_tfidf_train,y_train)

predictions = logistic_regression.predict(X_tfidf_test)

print(classification_report(predictions,y_test))

opinion_example ="prety bad"
vector_opinion_example = vectorizer.transform([opinion_example])
sentimiento=logistic_regression.predict(vector_opinion_example)
print('La opinion tiene un sentimiento: ', 'Positivo' if sentimiento == 1 else 'No positivo')

opinion_example ="pretty bad"
vector_opinion_example = vectorizer.transform([opinion_example])
logistic_regression.predict_proba(vector_opinion_example)

opinion_example ="very bad"
vector_opinion_example = vectorizer.transform([opinion_example])
predict_proba = logistic_regression.predict_proba(vector_opinion_example)
predict = logistic_regression.predict(vector_opinion_example)
predict, predict_proba

opinion_example ="bad bad bad"
vector_opinion_example = vectorizer.transform([opinion_example])
sentimiento=logistic_regression.predict(vector_opinion_example)
print('La opinion tiene un sentimiento: ', 'Negativo' if sentimiento == -1 else 'No Negativo')

opinion_example ="needs more work"
vector_opinion_example = vectorizer.transform([opinion_example])
sentimiento=logistic_regression.predict(vector_opinion_example)
print('La opinion tiene un sentimiento: ', 'Neutral' if sentimiento == 0 else 'No Neutral')

confusion_matrix = metrics.confusion_matrix(predictions,y_test)
print(confusion_matrix)

confusion_matrix = np.array(confusion_matrix)

fig, ax = plt.subplots(figsize=(8, 6))
sns.heatmap(confusion_matrix, annot=True, fmt="d", cmap="Blues", cbar=False, square=True)
ax.set_xlabel('Predicciones')
ax.set_ylabel('Valores verdaderos')
ax.set_title('Matriz de Confusión')
plt.show()

joblib.dump(logistic_regression,'Proyecto_modulo_7_final.pkl')

"""### usamos otro clasificador y vectorizador (RandomForest)"""

df_train

# Crear un vectorizador CountVectorizer para convertir las reseñas de texto en características numéricas
vectorizer2 = TfidfVectorizer()
X_train_vectorized2 = vectorizer2.fit_transform(df_train)
X_test_vectorized2 = vectorizer2.transform(df_test)

# Construir un clasificador RandomForest
random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
random_forest_classifier.fit(X_train_vectorized2, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred_rf2 = random_forest_classifier.predict(X_test_vectorized2)

# Evaluar el rendimiento del modelo RandomForest
accuracy_rf = classification_report(y_test, y_pred_rf2)
print(classification_report(y_pred_rf2,y_test))

confusion_matrix2 = metrics.confusion_matrix(y_pred_rf2,y_test)
print(confusion_matrix2)

fig, ax = plt.subplots(figsize=(8, 6))
sns.heatmap(confusion_matrix2, annot=True, fmt="d", cmap="Blues", cbar=False, square=True)
ax.set_xlabel('Predicciones')
ax.set_ylabel('Valores verdaderos')
ax.set_title('Matriz de Confusión')
plt.show()

"""Aquí hay algunas conclusiones que puedes extraer:

Clase -1:
Precision: 0.86 (1316 / (1316 + 74 + 263))
Recall: 0.79 (1316 / (1316 + 56 + 129))
F1-score: 0.82
Clase 0:
Precision: 0.74 (814 / (56 + 814 + 179))
Recall: 0.82 (814 / (74 + 814 + 86))
F1-score: 0.78
Clase 1:
Precision: 0.95 (4569 / (129 + 86 + 4569))
Recall: 0.91 (4569 / (263 + 179 + 4569))
F1-score: 0.93

Estos son algunos puntos clave:

El modelo tiene un buen rendimiento en la clasificación de la Clase 1 (Sentimiento Positivo), con alta precisión, recall y F1-score.
Para la Clase 0 (Sentimiento Neutral), la precisión es más baja, lo que indica que algunas predicciones positivas pueden ser falsas. Sin embargo, el recall es razonablemente alto, lo que sugiere que se están capturando la mayoría de las instancias reales de la clase.
Para la Clase -1 (Sentimiento Negativo), el rendimiento es equilibrado, pero puede haber algunos falsos positivos.

# Concluciones

Precision: La precisión mide cuántos de los casos clasificados como positivos son realmente positivos. En tu caso:

Para la clase -1 (Negativo), la precisión es del 80%. Esto significa que el 80% de las predicciones de negativos son correctas.

Para la clase 0 (Neutral), la precisión es del 78%. Esto significa que el 78% de las predicciones de neutrales son correctas.

Para la clase 1 (Positivo), la precisión es del 96%. Esto significa que el 96% de las predicciones de positivos son correctas.

Recall (Sensibilidad): La sensibilidad mide cuántos de los casos reales positivos fueron capturados por el modelo. En tu caso:

Para la clase -1 (Negativo), el recall es del 88%. Esto significa que el modelo captura el 88% de los casos reales negativos.

Para la clase 0 (Neutral), el recall es del 84%. Esto significa que el modelo captura el 84% de los casos reales neutrales.

Para la clase 1 (Positivo), el recall es del 91%. Esto significa que el modelo captura el 91% de los casos reales positivos.

F1-Score: Es una medida que combina precision y recall en un solo número. Cuanto más alto, mejor. En tu caso, los puntajes son bastante buenos:

F1-Score para la clase -1: 0.83

F1-Score para la clase 0: 0.80

F1-Score para la clase 1: 0.93

Accuracy (Exactitud): La exactitud mide cuántas de todas las predicciones son correctas. En tu caso, la exactitud es del 89%, lo cual es bastante sólido.
Macro Avg y Weighted Avg: Son promedios ponderados y no ponderados de precision, recall y f1-score. En general, todas las métricas son bastante altas, lo que sugiere un buen rendimiento del modelo.

Conclusiones:

El modelo es particularmente fuerte para predecir la clase 1 (Positivo).

Aunque la precisión y el recall para la clase -1 (Negativo) y 0 (Neutral) son un poco más bajos, todavía son bastante buenos.

La exactitud general del modelo es sólida, lo que sugiere que es capaz de hacer predicciones precisas en general.

Estos resultados sugieren que el modelo de regresión logística es efectivo para predecir los sentimientos en base a las reviews proporcionadas en tu conjunto de datos. Sin embargo, es importante tener en cuenta que estas conclusiones dependen de la calidad y representatividad del conjunto de datos utilizado para entrenar el modelo.

generar 3 casos de uso para una app de productividad, una para juego y una para familia realizar estos casos en particular con el cual podamos detectar el como se podria aplicar a un negocio el analisis de sentimientos. utilizando no un set de datos de training o test sino un caso particular en los ejemplos aterior mente dichos. recordar la concordancia entre la hipotesis y las concluciones.
buscar randomrorest para modelos de clasificacion sino usar otro
"""

review = ""
predecir(review, vectorizer, logistic_regression )